{
	"nodes":[
		{"id":"57638e10e91d2b6d","type":"group","x":-460,"y":-480,"width":871,"height":460,"label":"Read this first!"},
		{"id":"899e9e7ff12d6eee","type":"text","text":"## Coming up with ideas\nLooking at literature there seems to be two *flavors* of NLP:\n1. **Machine Learning**.\n2. **Rule-based Systems**.\n\n**When to go (1)**, when we have a lot of corpora or datasets to munch through.\n\n**When to go (2)**, when we need efficiency and the language in question is a **low-resource** language (a language with limited linguistic resources or data).","x":-20,"y":-460,"width":411,"height":420,"color":"2"},
		{"id":"4d3a68e18d7b6d7e","type":"text","text":"# Flavor 2: Rule-Based Systems","x":3,"y":246,"width":388,"height":94,"color":"6"},
		{"id":"ee1b787809a2e02f","type":"text","text":"# Flavor 1: Machine Learning","x":-440,"y":246,"width":388,"height":94,"color":"6"},
		{"id":"2de8a9e94191cca5","type":"text","text":"## Why?\n- Tagalog (and majority of the Philippine languages) are low-resource.\n- Majority of NLP research has its focus on machine learning, neural networks, etc. thus isolating those languages that are low-resource or people who do not have the capacity to train those.","x":3,"y":420,"width":388,"height":352},
		{"id":"c91193d89efd4bc0","type":"text","text":"# Ideas Board\nThis canvas and directory contains all ideas we have come up with.","x":-440,"y":-460,"width":304,"height":160,"color":"3"},
		{"id":"8dcd73243a887fa8","type":"text","text":"## Why?\n- The modern approach of NLP.\n- Is better than rule-based systems for language modelling.\n- **Issue**: requires a very large corpus and \"practice\" data.","x":-440,"y":420,"width":388,"height":241},
		{"id":"45b6374f11fe89af","type":"text","text":"# Flavor 3: Hybrid","x":-214,"y":920,"width":388,"height":46,"color":"6"},
		{"id":"38c56f424085a4ac","type":"text","text":"## Why?\n- Approach has both pros and cons of Machine Learning and Rule-based methods.","x":-214,"y":1040,"width":388,"height":168},
		{"id":"9a234fdb488a29fa","type":"text","text":"# Automata Extraction #scrapped\n>[!hint] Motivation and Background\n>Neural networks are not transparent (we don't really know what the neural network knows). Hence, if we have a neural network trained over an alphabet $\\Sigma$ we can extract what that neural network knows by constructing a DFA $A$ over $\\Sigma$.\n>\n>This extraction is done by Angluin's L* Algorithm and a minimally adequate teacher.\n\n**Idea**: By training a Transformer $T$ from Tagalog corpora and an oracle $\\mathcal{O}$, we may extract all the possible sentences $T$ knows as the DFA $A$.\n\n>[!warning] Scrapped... why?\n>Only works on regular languages. And, some Tagalog (or majority of human-languages) have some non-regular grammar rules.\n>\n>> Maybe we can take a subset of grammars and check if this actually works.\n\nReferences:\n[[[Ang87] Learning Regular Sets from Queries and Counterexamples.pdf|Ang87]], [[[GS22] Finite-State Text Processing.pdf|GS22]], [[[Kle51] Representation of Events in Nerve Nets and Finite Automata.pdf|Kle51]], [[[WGY20] Extracting Automata from Recurrent Neural Networks.pdf|WGY20]], [[[ZWS24] Automata Extraction from Transformers.pdf|ZWS24]].\n\nLong version: [[Automata Extraction]]","x":560,"y":643,"width":600,"height":600,"color":"1"},
		{"id":"d4f6d3eaf5d0e818","type":"text","text":"# Semantic Similarity\n**Essence**: the similarity of the meaning of two words. For phonetic languages (e.g., English and Tagalog) phonetic (sound) and orthographic (see) spelling of two words $\\alpha$ and $\\beta$ may provide some information on the similarity of the two\n- **Orthographic Similarity**: Levenshtein distance, longest common substring (LCS), and other dynamic programming methods.\n- **Phonetic Similarity**: The orthographic similarity of the two words given their orthographic spelling (grapheme to phoneme).","x":560,"y":103,"width":600,"height":380,"color":"4"},
		{"id":"113ce0740332bf2f","x":560,"y":1320,"width":600,"height":560,"color":"5","type":"text","text":"# Drug Similarity #proposal\nRead card on Semantic Similarity\n\n> [!hint] Motivation and Background\n> Confusable drugs are still prevalent and computing similarity rely on rule-based methods or language models. Issue with rule-based methods is that it may not be comprehensive (not inclusive of all medications) and machine learning methods require a lot of training (not friendly to low-resource languages).\n\n**Idea**: Using a recent BERT model by  [VSR+23](https://academic.oup.com/bib/article/24/4/bbad226/7197744) and previous literature on string matching algorithms. We can combine the two to create a method for drug similarity that is inclusive. \n\nLong version: [[Drug Similarity]]"}
	],
	"edges":[
		{"id":"91d263e2b0aadfbe","fromNode":"c91193d89efd4bc0","fromSide":"right","toNode":"899e9e7ff12d6eee","toSide":"left","toEnd":"none","color":"3"},
		{"id":"2c9a20975133f3c5","fromNode":"57638e10e91d2b6d","fromSide":"bottom","toNode":"4d3a68e18d7b6d7e","toSide":"top","toEnd":"none"},
		{"id":"4864f31bc009beb2","fromNode":"57638e10e91d2b6d","fromSide":"bottom","toNode":"ee1b787809a2e02f","toSide":"top","toEnd":"none"},
		{"id":"ea46f33222b3618c","fromNode":"4d3a68e18d7b6d7e","fromSide":"bottom","toNode":"2de8a9e94191cca5","toSide":"top","toEnd":"none"},
		{"id":"77cd335bba7f2d88","fromNode":"ee1b787809a2e02f","fromSide":"bottom","toNode":"8dcd73243a887fa8","toSide":"top","toEnd":"none"},
		{"id":"aa231600a1f40c71","fromNode":"8dcd73243a887fa8","fromSide":"bottom","toNode":"45b6374f11fe89af","toSide":"top","toEnd":"none"},
		{"id":"766ab5b771799b59","fromNode":"2de8a9e94191cca5","fromSide":"bottom","toNode":"45b6374f11fe89af","toSide":"top","toEnd":"none"},
		{"id":"dd253655e6e269c3","fromNode":"45b6374f11fe89af","fromSide":"bottom","toNode":"38c56f424085a4ac","toSide":"top","toEnd":"none"},
		{"id":"8b03eb0e5218e8a5","fromNode":"45b6374f11fe89af","fromSide":"right","toNode":"9a234fdb488a29fa","toSide":"left","toEnd":"none"},
		{"id":"1f0704e50301b94c","fromNode":"4d3a68e18d7b6d7e","fromSide":"right","toNode":"d4f6d3eaf5d0e818","toSide":"left"},
		{"id":"c954116045cb484b","fromNode":"45b6374f11fe89af","fromSide":"right","toNode":"113ce0740332bf2f","toSide":"left"}
	]
}